{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Index</th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>...</th>\n",
       "      <th>PO7</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.921</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-19.847</td>\n",
       "      <td>8.148</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>1.129</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.157</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>-9.033</td>\n",
       "      <td>-2.421</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-8.901</td>\n",
       "      <td>-5.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.433</td>\n",
       "      <td>3.276</td>\n",
       "      <td>-12.522</td>\n",
       "      <td>1.801</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>0.641</td>\n",
       "      <td>...</td>\n",
       "      <td>10.254</td>\n",
       "      <td>7.111</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-8.708</td>\n",
       "      <td>-12.451</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-7.924</td>\n",
       "      <td>-2.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.574</td>\n",
       "      <td>5.717</td>\n",
       "      <td>1.149</td>\n",
       "      <td>-2.594</td>\n",
       "      <td>-1.658</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465</td>\n",
       "      <td>-2.655</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-9.196</td>\n",
       "      <td>-11.963</td>\n",
       "      <td>-4.862</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-3.042</td>\n",
       "      <td>1.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.239</td>\n",
       "      <td>7.670</td>\n",
       "      <td>14.821</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>...</td>\n",
       "      <td>5.371</td>\n",
       "      <td>-7.050</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-6.755</td>\n",
       "      <td>-8.545</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>4.771</td>\n",
       "      <td>5.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11.587</td>\n",
       "      <td>9.623</td>\n",
       "      <td>20.681</td>\n",
       "      <td>-5.035</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0.641</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.207</td>\n",
       "      <td>-4.120</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-3.337</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>-1.933</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>11.607</td>\n",
       "      <td>9.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Subject  Trial  Index     FP1    FP2      F7     F8    AF1  \\\n",
       "0           0  co2a0000364      0      1  -8.921  0.834 -19.847  8.148 -2.146   \n",
       "1           1  co2a0000364      0      2  -8.433  3.276 -12.522  1.801 -2.146   \n",
       "2           2  co2a0000364      0      3  -2.574  5.717   1.149 -2.594 -1.658   \n",
       "3           3  co2a0000364      0      4   5.239  7.670  14.821 -4.547 -0.682   \n",
       "4           4  co2a0000364      0      5  11.587  9.623  20.681 -5.035  2.248   \n",
       "\n",
       "     AF2  ...     PO7    PO8    FCZ    POZ      OZ     P2     P1    CPZ  \\\n",
       "0  1.129  ...   3.906  5.157  1.048 -6.266  -9.033 -2.421 -4.313 -0.478   \n",
       "1  0.641  ...  10.254  7.111  0.559 -8.708 -12.451 -3.886 -5.290 -0.966   \n",
       "2 -0.336  ...   1.465 -2.655  0.559 -9.196 -11.963 -4.862 -5.290 -0.966   \n",
       "3 -0.824  ...   5.371 -7.050  0.559 -6.755  -8.545 -3.886 -4.313 -0.966   \n",
       "4  0.641  ... -12.207 -4.120  1.048 -3.337  -3.662 -1.933 -2.360 -0.478   \n",
       "\n",
       "       nd      Y  \n",
       "0  -8.901 -5.636  \n",
       "1  -7.924 -2.706  \n",
       "2  -3.042  1.689  \n",
       "3   4.771  5.595  \n",
       "4  11.607  9.013  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filen = \"CEM_Train_Alcoh.csv\"\n",
    "df = pd.read_csv(filen)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         alcoholic\n",
       "1         alcoholic\n",
       "2         alcoholic\n",
       "3         alcoholic\n",
       "4         alcoholic\n",
       "5         alcoholic\n",
       "6         alcoholic\n",
       "7         alcoholic\n",
       "8         alcoholic\n",
       "9         alcoholic\n",
       "10        alcoholic\n",
       "11        alcoholic\n",
       "12        alcoholic\n",
       "13        alcoholic\n",
       "14        alcoholic\n",
       "15        alcoholic\n",
       "16        alcoholic\n",
       "17        alcoholic\n",
       "18        alcoholic\n",
       "19        alcoholic\n",
       "20        alcoholic\n",
       "21        alcoholic\n",
       "22        alcoholic\n",
       "23        alcoholic\n",
       "24        alcoholic\n",
       "25        alcoholic\n",
       "26        alcoholic\n",
       "27        alcoholic\n",
       "28        alcoholic\n",
       "29        alcoholic\n",
       "            ...    \n",
       "153570      control\n",
       "153571      control\n",
       "153572      control\n",
       "153573      control\n",
       "153574      control\n",
       "153575      control\n",
       "153576      control\n",
       "153577      control\n",
       "153578      control\n",
       "153579      control\n",
       "153580      control\n",
       "153581      control\n",
       "153582      control\n",
       "153583      control\n",
       "153584      control\n",
       "153585      control\n",
       "153586      control\n",
       "153587      control\n",
       "153588      control\n",
       "153589      control\n",
       "153590      control\n",
       "153591      control\n",
       "153592      control\n",
       "153593      control\n",
       "153594      control\n",
       "153595      control\n",
       "153596      control\n",
       "153597      control\n",
       "153598      control\n",
       "153599      control\n",
       "Name: label, Length: 153600, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = df[\"Subject\"]\n",
    "y2 = []\n",
    "for s in y1:\n",
    "    if 'a' in s:\n",
    "        y2.append(\"alcoholic\")\n",
    "    else:\n",
    "        y2.append(\"control\")\n",
    "\n",
    "y4 = pd.DataFrame({\"label\":y2})\n",
    "y = y4[\"label\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>FZ</th>\n",
       "      <th>F4</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC6</th>\n",
       "      <th>...</th>\n",
       "      <th>PO7</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.921</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-19.847</td>\n",
       "      <td>8.148</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>1.129</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>3.408</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>4.832</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.157</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>-9.033</td>\n",
       "      <td>-2.421</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-8.901</td>\n",
       "      <td>-5.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.433</td>\n",
       "      <td>3.276</td>\n",
       "      <td>-12.522</td>\n",
       "      <td>1.801</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>1.455</td>\n",
       "      <td>0.397</td>\n",
       "      <td>6.297</td>\n",
       "      <td>...</td>\n",
       "      <td>10.254</td>\n",
       "      <td>7.111</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-8.708</td>\n",
       "      <td>-12.451</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-7.924</td>\n",
       "      <td>-2.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.574</td>\n",
       "      <td>5.717</td>\n",
       "      <td>1.149</td>\n",
       "      <td>-2.594</td>\n",
       "      <td>-1.658</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-1.048</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>5.809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465</td>\n",
       "      <td>-2.655</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-9.196</td>\n",
       "      <td>-11.963</td>\n",
       "      <td>-4.862</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-3.042</td>\n",
       "      <td>1.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.239</td>\n",
       "      <td>7.670</td>\n",
       "      <td>14.821</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-3.510</td>\n",
       "      <td>3.367</td>\n",
       "      <td>...</td>\n",
       "      <td>5.371</td>\n",
       "      <td>-7.050</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-6.755</td>\n",
       "      <td>-8.545</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>4.771</td>\n",
       "      <td>5.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.587</td>\n",
       "      <td>9.623</td>\n",
       "      <td>20.681</td>\n",
       "      <td>-5.035</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1.943</td>\n",
       "      <td>-5.463</td>\n",
       "      <td>1.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.207</td>\n",
       "      <td>-4.120</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-3.337</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>-1.933</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>11.607</td>\n",
       "      <td>9.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FP1    FP2      F7     F8    AF1    AF2     FZ     F4     F3    FC6  \\\n",
       "0  -8.921  0.834 -19.847  8.148 -2.146  1.129 -0.071  3.408 -0.092  4.832   \n",
       "1  -8.433  3.276 -12.522  1.801 -2.146  0.641 -0.559  1.455  0.397  6.297   \n",
       "2  -2.574  5.717   1.149 -2.594 -1.658 -0.336 -1.048  0.478 -1.068  5.809   \n",
       "3   5.239  7.670  14.821 -4.547 -0.682 -0.824 -0.559  0.966 -3.510  3.367   \n",
       "4  11.587  9.623  20.681 -5.035  2.248  0.641  0.905  1.943 -5.463  1.414   \n",
       "\n",
       "   ...     PO7    PO8    FCZ    POZ      OZ     P2     P1    CPZ      nd  \\\n",
       "0  ...   3.906  5.157  1.048 -6.266  -9.033 -2.421 -4.313 -0.478  -8.901   \n",
       "1  ...  10.254  7.111  0.559 -8.708 -12.451 -3.886 -5.290 -0.966  -7.924   \n",
       "2  ...   1.465 -2.655  0.559 -9.196 -11.963 -4.862 -5.290 -0.966  -3.042   \n",
       "3  ...   5.371 -7.050  0.559 -6.755  -8.545 -3.886 -4.313 -0.966   4.771   \n",
       "4  ... -12.207 -4.120  1.048 -3.337  -3.662 -1.933 -2.360 -0.478  11.607   \n",
       "\n",
       "       Y  \n",
       "0 -5.636  \n",
       "1 -2.706  \n",
       "2  1.689  \n",
       "3  5.595  \n",
       "4  9.013  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,4:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153600, 64) (153600,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=64))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/60\n",
      " - 8s - loss: 0.3085 - accuracy: 0.8573\n",
      "Epoch 2/60\n",
      " - 9s - loss: 0.1548 - accuracy: 0.9377\n",
      "Epoch 3/60\n",
      " - 9s - loss: 0.1160 - accuracy: 0.9547\n",
      "Epoch 4/60\n",
      " - 12s - loss: 0.0962 - accuracy: 0.9630\n",
      "Epoch 5/60\n",
      " - 7s - loss: 0.0817 - accuracy: 0.9690\n",
      "Epoch 6/60\n",
      " - 11s - loss: 0.0732 - accuracy: 0.9725\n",
      "Epoch 7/60\n",
      " - 9s - loss: 0.0650 - accuracy: 0.9757\n",
      "Epoch 8/60\n",
      " - 9s - loss: 0.0599 - accuracy: 0.9777\n",
      "Epoch 9/60\n",
      " - 11s - loss: 0.0554 - accuracy: 0.9794\n",
      "Epoch 10/60\n",
      " - 8s - loss: 0.0494 - accuracy: 0.9814\n",
      "Epoch 11/60\n",
      " - 7s - loss: 0.0475 - accuracy: 0.9824\n",
      "Epoch 12/60\n",
      " - 7s - loss: 0.0440 - accuracy: 0.9836\n",
      "Epoch 13/60\n",
      " - 7s - loss: 0.0419 - accuracy: 0.9844\n",
      "Epoch 14/60\n",
      " - 7s - loss: 0.0385 - accuracy: 0.9857\n",
      "Epoch 15/60\n",
      " - 7s - loss: 0.0360 - accuracy: 0.9869\n",
      "Epoch 16/60\n",
      " - 7s - loss: 0.0348 - accuracy: 0.9874\n",
      "Epoch 17/60\n",
      " - 10s - loss: 0.0335 - accuracy: 0.9877\n",
      "Epoch 18/60\n",
      " - 8s - loss: 0.0303 - accuracy: 0.9890\n",
      "Epoch 19/60\n",
      " - 13s - loss: 0.0314 - accuracy: 0.9887\n",
      "Epoch 20/60\n",
      " - 7s - loss: 0.0283 - accuracy: 0.9902\n",
      "Epoch 21/60\n",
      " - 8s - loss: 0.0263 - accuracy: 0.9905\n",
      "Epoch 22/60\n",
      " - 7s - loss: 0.0263 - accuracy: 0.9907\n",
      "Epoch 23/60\n",
      " - 7s - loss: 0.0271 - accuracy: 0.9909\n",
      "Epoch 24/60\n",
      " - 9s - loss: 0.0241 - accuracy: 0.9914\n",
      "Epoch 25/60\n",
      " - 9s - loss: 0.0220 - accuracy: 0.9920\n",
      "Epoch 26/60\n",
      " - 7s - loss: 0.0264 - accuracy: 0.9911\n",
      "Epoch 27/60\n",
      " - 7s - loss: 0.0227 - accuracy: 0.9924\n",
      "Epoch 28/60\n",
      " - 6s - loss: 0.0196 - accuracy: 0.9932\n",
      "Epoch 29/60\n",
      " - 6s - loss: 0.0222 - accuracy: 0.9920\n",
      "Epoch 30/60\n",
      " - 6s - loss: 0.0195 - accuracy: 0.9931\n",
      "Epoch 31/60\n",
      " - 7s - loss: 0.0198 - accuracy: 0.9934\n",
      "Epoch 32/60\n",
      " - 15s - loss: 0.0193 - accuracy: 0.9931\n",
      "Epoch 33/60\n",
      " - 6s - loss: 0.0181 - accuracy: 0.9938\n",
      "Epoch 34/60\n",
      " - 5s - loss: 0.0194 - accuracy: 0.9930\n",
      "Epoch 35/60\n",
      " - 5s - loss: 0.0160 - accuracy: 0.9942\n",
      "Epoch 36/60\n",
      " - 5s - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 37/60\n",
      " - 5s - loss: 0.0173 - accuracy: 0.9941\n",
      "Epoch 38/60\n",
      " - 5s - loss: 0.0165 - accuracy: 0.9943\n",
      "Epoch 39/60\n",
      " - 5s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 40/60\n",
      " - 5s - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 41/60\n",
      " - 5s - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 42/60\n",
      " - 7s - loss: 0.0144 - accuracy: 0.9950\n",
      "Epoch 43/60\n",
      " - 13s - loss: 0.0142 - accuracy: 0.9950\n",
      "Epoch 44/60\n",
      " - 10s - loss: 0.0144 - accuracy: 0.9951\n",
      "Epoch 45/60\n",
      " - 8s - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 46/60\n",
      " - 8s - loss: 0.0137 - accuracy: 0.9953\n",
      "Epoch 47/60\n",
      " - 5s - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 48/60\n",
      " - 6s - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 49/60\n",
      " - 5s - loss: 0.0128 - accuracy: 0.9956\n",
      "Epoch 50/60\n",
      " - 5s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 51/60\n",
      " - 6s - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 52/60\n",
      " - 5s - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 53/60\n",
      " - 6s - loss: 0.0116 - accuracy: 0.9962\n",
      "Epoch 54/60\n",
      " - 5s - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 55/60\n",
      " - 5s - loss: 0.0112 - accuracy: 0.9963\n",
      "Epoch 56/60\n",
      " - 6s - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 57/60\n",
      " - 6s - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 58/60\n",
      " - 7s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 59/60\n",
      " - 5s - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 60/60\n",
      " - 5s - loss: 0.0122 - accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x271165126a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.05762955266772487, Accuracy: 0.9850260615348816\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['control' 'control' 'control' 'alcoholic' 'control']\n",
      "Actual Labels: ['control', 'control', 'control', 'alcoholic', 'control']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"alcoholic_model_trained2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Convolutional Neural Networks in Keras for Time Sequences\n",
    "\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "TIME_PERIODS = 1\n",
    "num_sensors = 64\n",
    "input_shape = 64\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_8 (Reshape)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1, 100)            6500      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1, 100)            10100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1, 160)            16160     \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1, 160)            25760     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 322       \n",
      "=================================================================\n",
      "Total params: 58,842\n",
      "Trainable params: 58,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "model_m.add(Conv1D(100, 1, activation='relu', input_shape=(TIME_PERIODS, num_sensors)))\n",
    "model_m.add(Conv1D(100, 1, activation='relu'))\n",
    "model_m.add(MaxPooling1D(1))\n",
    "model_m.add(Conv1D(160, 1, activation='relu'))\n",
    "model_m.add(Conv1D(160, 1, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D())\n",
    "model_m.add(Dropout(0.5))\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92160 samples, validate on 23040 samples\n",
      "Epoch 1/50\n",
      "92160/92160 [==============================] - 5s 49us/step - loss: 0.4625 - accuracy: 0.7633 - val_loss: 0.3127 - val_accuracy: 0.8613\n",
      "Epoch 2/50\n",
      " 4400/92160 [>.............................] - ETA: 3s - loss: 0.2979 - accuracy: 0.8691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92160/92160 [==============================] - 4s 39us/step - loss: 0.2482 - accuracy: 0.8945 - val_loss: 0.2055 - val_accuracy: 0.9158\n",
      "Epoch 3/50\n",
      "92160/92160 [==============================] - 4s 47us/step - loss: 0.1785 - accuracy: 0.9276 - val_loss: 0.1675 - val_accuracy: 0.9330\n",
      "Epoch 4/50\n",
      "92160/92160 [==============================] - 4s 40us/step - loss: 0.1358 - accuracy: 0.9463 - val_loss: 0.1390 - val_accuracy: 0.9456\n",
      "Epoch 5/50\n",
      "92160/92160 [==============================] - 4s 40us/step - loss: 0.1111 - accuracy: 0.9568 - val_loss: 0.1208 - val_accuracy: 0.9516\n",
      "Epoch 6/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0908 - accuracy: 0.9653 - val_loss: 0.1129 - val_accuracy: 0.9569\n",
      "Epoch 7/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0800 - accuracy: 0.9697 - val_loss: 0.1106 - val_accuracy: 0.9579\n",
      "Epoch 8/50\n",
      "92160/92160 [==============================] - 4s 40us/step - loss: 0.0683 - accuracy: 0.9750 - val_loss: 0.0971 - val_accuracy: 0.9635\n",
      "Epoch 9/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0588 - accuracy: 0.9779 - val_loss: 0.0958 - val_accuracy: 0.9640\n",
      "Epoch 10/50\n",
      "92160/92160 [==============================] - 4s 40us/step - loss: 0.0540 - accuracy: 0.9798 - val_loss: 0.0816 - val_accuracy: 0.9694\n",
      "Epoch 11/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0508 - accuracy: 0.9812 - val_loss: 0.0851 - val_accuracy: 0.9705\n",
      "Epoch 12/50\n",
      "92160/92160 [==============================] - 4s 40us/step - loss: 0.0433 - accuracy: 0.9839 - val_loss: 0.0786 - val_accuracy: 0.9711\n",
      "Epoch 13/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0397 - accuracy: 0.9857 - val_loss: 0.0906 - val_accuracy: 0.9691\n",
      "Epoch 14/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9719\n",
      "Epoch 15/50\n",
      "92160/92160 [==============================] - 4s 45us/step - loss: 0.0336 - accuracy: 0.9876 - val_loss: 0.0806 - val_accuracy: 0.9749\n",
      "Epoch 16/50\n",
      "92160/92160 [==============================] - 4s 47us/step - loss: 0.0324 - accuracy: 0.9879 - val_loss: 0.0806 - val_accuracy: 0.9732\n",
      "Epoch 17/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.0786 - val_accuracy: 0.9740\n",
      "Epoch 18/50\n",
      "92160/92160 [==============================] - 4s 45us/step - loss: 0.0273 - accuracy: 0.9899 - val_loss: 0.0791 - val_accuracy: 0.9734\n",
      "Epoch 19/50\n",
      "92160/92160 [==============================] - 4s 47us/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.0859 - val_accuracy: 0.9731\n",
      "Epoch 20/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0243 - accuracy: 0.9910 - val_loss: 0.0801 - val_accuracy: 0.9751\n",
      "Epoch 21/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.0721 - val_accuracy: 0.9781\n",
      "Epoch 22/50\n",
      "92160/92160 [==============================] - 5s 50us/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.0751 - val_accuracy: 0.9766\n",
      "Epoch 23/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0218 - accuracy: 0.9917 - val_loss: 0.0780 - val_accuracy: 0.9760\n",
      "Epoch 24/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.0752 - val_accuracy: 0.9780\n",
      "Epoch 25/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.0828 - val_accuracy: 0.9764\n",
      "Epoch 26/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.0836 - val_accuracy: 0.9759\n",
      "Epoch 27/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0774 - val_accuracy: 0.9793\n",
      "Epoch 28/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.0844 - val_accuracy: 0.9763\n",
      "Epoch 29/50\n",
      "92160/92160 [==============================] - 4s 48us/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 0.0779 - val_accuracy: 0.9771\n",
      "Epoch 30/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0838 - val_accuracy: 0.9771\n",
      "Epoch 31/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0719 - val_accuracy: 0.9797\n",
      "Epoch 32/50\n",
      "92160/92160 [==============================] - 4s 46us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0767 - val_accuracy: 0.9783\n",
      "Epoch 33/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0808 - val_accuracy: 0.9777\n",
      "Epoch 34/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.0792 - val_accuracy: 0.9786\n",
      "Epoch 35/50\n",
      "92160/92160 [==============================] - 5s 52us/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0777 - val_accuracy: 0.9763\n",
      "Epoch 36/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0711 - val_accuracy: 0.9803\n",
      "Epoch 37/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0832 - val_accuracy: 0.9789\n",
      "Epoch 38/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0855 - val_accuracy: 0.9795\n",
      "Epoch 39/50\n",
      "92160/92160 [==============================] - 4s 41us/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0819 - val_accuracy: 0.9793\n",
      "Epoch 40/50\n",
      "92160/92160 [==============================] - 4s 42us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0762 - val_accuracy: 0.9803\n",
      "Epoch 41/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0694 - val_accuracy: 0.9811\n",
      "Epoch 42/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0787 - val_accuracy: 0.9787\n",
      "Epoch 43/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0737 - val_accuracy: 0.9809\n",
      "Epoch 44/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0772 - val_accuracy: 0.9806\n",
      "Epoch 45/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0784 - val_accuracy: 0.9811\n",
      "Epoch 46/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0826 - val_accuracy: 0.9796\n",
      "Epoch 47/50\n",
      "92160/92160 [==============================] - 4s 47us/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.0741 - val_accuracy: 0.9826\n",
      "Epoch 48/50\n",
      "92160/92160 [==============================] - 4s 43us/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0781 - val_accuracy: 0.9811\n",
      "Epoch 49/50\n",
      "92160/92160 [==============================] - 4s 44us/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0830 - val_accuracy: 0.9790\n",
      "Epoch 50/50\n",
      "92160/92160 [==============================] - 4s 46us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks_list = [keras.callbacks.ModelCheckpoint(filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                                                  monitor='val_loss', save_best_only=True),\n",
    "                  keras.callbacks.EarlyStopping(monitor='acc', patience=1)]\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model_m.fit(X_train_scaled,\n",
    "                      y_train_categorical,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.07117326777189997, Accuracy: 0.9821354150772095\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model_m.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_m.save(\"alcoholic_model_1DCNN1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
