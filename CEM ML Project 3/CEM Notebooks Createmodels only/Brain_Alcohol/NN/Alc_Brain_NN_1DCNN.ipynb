{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trial</th>\n",
       "      <th>subject</th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>FZ</th>\n",
       "      <th>...</th>\n",
       "      <th>PO7</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>-8.921</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-19.847</td>\n",
       "      <td>8.148</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>1.129</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.157</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>-9.033</td>\n",
       "      <td>-2.421</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-8.901</td>\n",
       "      <td>-5.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>-8.433</td>\n",
       "      <td>3.276</td>\n",
       "      <td>-12.522</td>\n",
       "      <td>1.801</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>...</td>\n",
       "      <td>10.254</td>\n",
       "      <td>7.111</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-8.708</td>\n",
       "      <td>-12.451</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-7.924</td>\n",
       "      <td>-2.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>-2.574</td>\n",
       "      <td>5.717</td>\n",
       "      <td>1.149</td>\n",
       "      <td>-2.594</td>\n",
       "      <td>-1.658</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-1.048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465</td>\n",
       "      <td>-2.655</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-9.196</td>\n",
       "      <td>-11.963</td>\n",
       "      <td>-4.862</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-3.042</td>\n",
       "      <td>1.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>5.239</td>\n",
       "      <td>7.670</td>\n",
       "      <td>14.821</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>...</td>\n",
       "      <td>5.371</td>\n",
       "      <td>-7.050</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-6.755</td>\n",
       "      <td>-8.545</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>4.771</td>\n",
       "      <td>5.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>co2a0000364</td>\n",
       "      <td>11.587</td>\n",
       "      <td>9.623</td>\n",
       "      <td>20.681</td>\n",
       "      <td>-5.035</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.905</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.207</td>\n",
       "      <td>-4.120</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-3.337</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>-1.933</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>11.607</td>\n",
       "      <td>9.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  trial      subject     FP1    FP2      F7     F8    AF1    AF2  \\\n",
       "0           0      0  co2a0000364  -8.921  0.834 -19.847  8.148 -2.146  1.129   \n",
       "1           1      0  co2a0000364  -8.433  3.276 -12.522  1.801 -2.146  0.641   \n",
       "2           2      0  co2a0000364  -2.574  5.717   1.149 -2.594 -1.658 -0.336   \n",
       "3           3      0  co2a0000364   5.239  7.670  14.821 -4.547 -0.682 -0.824   \n",
       "4           4      0  co2a0000364  11.587  9.623  20.681 -5.035  2.248  0.641   \n",
       "\n",
       "      FZ  ...     PO7    PO8    FCZ    POZ      OZ     P2     P1    CPZ  \\\n",
       "0 -0.071  ...   3.906  5.157  1.048 -6.266  -9.033 -2.421 -4.313 -0.478   \n",
       "1 -0.559  ...  10.254  7.111  0.559 -8.708 -12.451 -3.886 -5.290 -0.966   \n",
       "2 -1.048  ...   1.465 -2.655  0.559 -9.196 -11.963 -4.862 -5.290 -0.966   \n",
       "3 -0.559  ...   5.371 -7.050  0.559 -6.755  -8.545 -3.886 -4.313 -0.966   \n",
       "4  0.905  ... -12.207 -4.120  1.048 -3.337  -3.662 -1.933 -2.360 -0.478   \n",
       "\n",
       "       nd      Y  \n",
       "0  -8.901 -5.636  \n",
       "1  -7.924 -2.706  \n",
       "2  -3.042  1.689  \n",
       "3   4.771  5.595  \n",
       "4  11.607  9.013  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filen = \"../data/alcoholism_eeg.csv\"\n",
    "df = pd.read_csv(filen)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          alcoholic\n",
       "1          alcoholic\n",
       "2          alcoholic\n",
       "3          alcoholic\n",
       "4          alcoholic\n",
       "5          alcoholic\n",
       "6          alcoholic\n",
       "7          alcoholic\n",
       "8          alcoholic\n",
       "9          alcoholic\n",
       "10         alcoholic\n",
       "11         alcoholic\n",
       "12         alcoholic\n",
       "13         alcoholic\n",
       "14         alcoholic\n",
       "15         alcoholic\n",
       "16         alcoholic\n",
       "17         alcoholic\n",
       "18         alcoholic\n",
       "19         alcoholic\n",
       "20         alcoholic\n",
       "21         alcoholic\n",
       "22         alcoholic\n",
       "23         alcoholic\n",
       "24         alcoholic\n",
       "25         alcoholic\n",
       "26         alcoholic\n",
       "27         alcoholic\n",
       "28         alcoholic\n",
       "29         alcoholic\n",
       "             ...    \n",
       "2830562      control\n",
       "2830563      control\n",
       "2830564      control\n",
       "2830565      control\n",
       "2830566      control\n",
       "2830567      control\n",
       "2830568      control\n",
       "2830569      control\n",
       "2830570      control\n",
       "2830571      control\n",
       "2830572      control\n",
       "2830573      control\n",
       "2830574      control\n",
       "2830575      control\n",
       "2830576      control\n",
       "2830577      control\n",
       "2830578      control\n",
       "2830579      control\n",
       "2830580      control\n",
       "2830581      control\n",
       "2830582      control\n",
       "2830583      control\n",
       "2830584      control\n",
       "2830585      control\n",
       "2830586      control\n",
       "2830587      control\n",
       "2830588      control\n",
       "2830589      control\n",
       "2830590      control\n",
       "2830591      control\n",
       "Name: label, Length: 2830592, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = df[\"subject\"]\n",
    "y2 = []\n",
    "for s in y1:\n",
    "    if 'a' in s:\n",
    "        y2.append(\"alcoholic\")\n",
    "    else:\n",
    "        y2.append(\"control\")\n",
    "\n",
    "y4 = pd.DataFrame({\"label\":y2})\n",
    "y = y4[\"label\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>FZ</th>\n",
       "      <th>F4</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC6</th>\n",
       "      <th>...</th>\n",
       "      <th>PO7</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.921</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-19.847</td>\n",
       "      <td>8.148</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>1.129</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>3.408</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>4.832</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.157</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>-9.033</td>\n",
       "      <td>-2.421</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-8.901</td>\n",
       "      <td>-5.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.433</td>\n",
       "      <td>3.276</td>\n",
       "      <td>-12.522</td>\n",
       "      <td>1.801</td>\n",
       "      <td>-2.146</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>1.455</td>\n",
       "      <td>0.397</td>\n",
       "      <td>6.297</td>\n",
       "      <td>...</td>\n",
       "      <td>10.254</td>\n",
       "      <td>7.111</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-8.708</td>\n",
       "      <td>-12.451</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-7.924</td>\n",
       "      <td>-2.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.574</td>\n",
       "      <td>5.717</td>\n",
       "      <td>1.149</td>\n",
       "      <td>-2.594</td>\n",
       "      <td>-1.658</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-1.048</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>5.809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465</td>\n",
       "      <td>-2.655</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-9.196</td>\n",
       "      <td>-11.963</td>\n",
       "      <td>-4.862</td>\n",
       "      <td>-5.290</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-3.042</td>\n",
       "      <td>1.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.239</td>\n",
       "      <td>7.670</td>\n",
       "      <td>14.821</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-3.510</td>\n",
       "      <td>3.367</td>\n",
       "      <td>...</td>\n",
       "      <td>5.371</td>\n",
       "      <td>-7.050</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-6.755</td>\n",
       "      <td>-8.545</td>\n",
       "      <td>-3.886</td>\n",
       "      <td>-4.313</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>4.771</td>\n",
       "      <td>5.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.587</td>\n",
       "      <td>9.623</td>\n",
       "      <td>20.681</td>\n",
       "      <td>-5.035</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1.943</td>\n",
       "      <td>-5.463</td>\n",
       "      <td>1.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.207</td>\n",
       "      <td>-4.120</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-3.337</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>-1.933</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>11.607</td>\n",
       "      <td>9.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FP1    FP2      F7     F8    AF1    AF2     FZ     F4     F3    FC6  \\\n",
       "0  -8.921  0.834 -19.847  8.148 -2.146  1.129 -0.071  3.408 -0.092  4.832   \n",
       "1  -8.433  3.276 -12.522  1.801 -2.146  0.641 -0.559  1.455  0.397  6.297   \n",
       "2  -2.574  5.717   1.149 -2.594 -1.658 -0.336 -1.048  0.478 -1.068  5.809   \n",
       "3   5.239  7.670  14.821 -4.547 -0.682 -0.824 -0.559  0.966 -3.510  3.367   \n",
       "4  11.587  9.623  20.681 -5.035  2.248  0.641  0.905  1.943 -5.463  1.414   \n",
       "\n",
       "   ...     PO7    PO8    FCZ    POZ      OZ     P2     P1    CPZ      nd  \\\n",
       "0  ...   3.906  5.157  1.048 -6.266  -9.033 -2.421 -4.313 -0.478  -8.901   \n",
       "1  ...  10.254  7.111  0.559 -8.708 -12.451 -3.886 -5.290 -0.966  -7.924   \n",
       "2  ...   1.465 -2.655  0.559 -9.196 -11.963 -4.862 -5.290 -0.966  -3.042   \n",
       "3  ...   5.371 -7.050  0.559 -6.755  -8.545 -3.886 -4.313 -0.966   4.771   \n",
       "4  ... -12.207 -4.120  1.048 -3.337  -3.662 -1.933 -2.360 -0.478  11.607   \n",
       "\n",
       "       Y  \n",
       "0 -5.636  \n",
       "1 -2.706  \n",
       "2  1.689  \n",
       "3  5.595  \n",
       "4  9.013  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,3:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AB_NN_label_encoder.bin']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the label_encoder\n",
    "from sklearn.externals.joblib import dump, load\n",
    "dump(label_encoder, 'AB_NN_label_encoder.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06062647,  0.19750515, -0.68937446, ..., -0.96398877,\n",
       "         0.17562892, -0.34600266],\n",
       "       [ 0.33854902,  0.54276242, -0.29877757, ..., -1.58578933,\n",
       "        -2.91726875, -0.39551035],\n",
       "       [ 0.38516171,  1.68492166, -1.47366455, ..., -1.52908727,\n",
       "        -1.39377326, -1.26620607],\n",
       "       ...,\n",
       "       [ 0.70511488,  0.58742506,  0.60913187, ..., -0.06060001,\n",
       "         0.76820206,  0.80692864],\n",
       "       [-0.57350986, -0.68753026, -0.82870748, ...,  0.49258144,\n",
       "        -0.63723714, -0.65299208],\n",
       "       [-0.01477975, -0.14643483,  0.55711421, ...,  0.85835779,\n",
       "        -0.25150277,  0.46107011]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>FZ</th>\n",
       "      <th>F4</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC6</th>\n",
       "      <th>...</th>\n",
       "      <th>PO7</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151074</th>\n",
       "      <td>-42.582</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>5.910</td>\n",
       "      <td>5.697</td>\n",
       "      <td>8.382</td>\n",
       "      <td>7.619</td>\n",
       "      <td>6.877</td>\n",
       "      <td>6.409</td>\n",
       "      <td>9.013</td>\n",
       "      <td>5.056</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.472</td>\n",
       "      <td>3.174</td>\n",
       "      <td>3.611</td>\n",
       "      <td>0.397</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.587</td>\n",
       "      <td>-2.299</td>\n",
       "      <td>-1.780</td>\n",
       "      <td>3.560</td>\n",
       "      <td>8.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115630</th>\n",
       "      <td>11.587</td>\n",
       "      <td>5.473</td>\n",
       "      <td>15.188</td>\n",
       "      <td>11.983</td>\n",
       "      <td>13.550</td>\n",
       "      <td>6.907</td>\n",
       "      <td>5.229</td>\n",
       "      <td>0.122</td>\n",
       "      <td>5.615</td>\n",
       "      <td>2.543</td>\n",
       "      <td>...</td>\n",
       "      <td>4.415</td>\n",
       "      <td>4.700</td>\n",
       "      <td>3.347</td>\n",
       "      <td>6.460</td>\n",
       "      <td>5.585</td>\n",
       "      <td>4.506</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>17.385</td>\n",
       "      <td>18.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604605</th>\n",
       "      <td>-5.554</td>\n",
       "      <td>-8.077</td>\n",
       "      <td>-1.465</td>\n",
       "      <td>-2.136</td>\n",
       "      <td>-7.853</td>\n",
       "      <td>-6.989</td>\n",
       "      <td>-5.717</td>\n",
       "      <td>1.088</td>\n",
       "      <td>-5.656</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>-8.321</td>\n",
       "      <td>-1.221</td>\n",
       "      <td>-14.781</td>\n",
       "      <td>-14.191</td>\n",
       "      <td>-11.597</td>\n",
       "      <td>-7.935</td>\n",
       "      <td>-3.001</td>\n",
       "      <td>-8.006</td>\n",
       "      <td>-4.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805772</th>\n",
       "      <td>-3.296</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>5.910</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>-2.736</td>\n",
       "      <td>-7.355</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-6.317</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>...</td>\n",
       "      <td>12.349</td>\n",
       "      <td>18.545</td>\n",
       "      <td>-5.086</td>\n",
       "      <td>8.565</td>\n",
       "      <td>10.010</td>\n",
       "      <td>8.097</td>\n",
       "      <td>8.596</td>\n",
       "      <td>6.053</td>\n",
       "      <td>8.474</td>\n",
       "      <td>8.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490280</th>\n",
       "      <td>-4.547</td>\n",
       "      <td>-3.174</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-6.042</td>\n",
       "      <td>-5.778</td>\n",
       "      <td>-4.639</td>\n",
       "      <td>-9.084</td>\n",
       "      <td>-3.082</td>\n",
       "      <td>-6.856</td>\n",
       "      <td>-1.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-11.902</td>\n",
       "      <td>-6.999</td>\n",
       "      <td>8.667</td>\n",
       "      <td>2.665</td>\n",
       "      <td>11.709</td>\n",
       "      <td>9.511</td>\n",
       "      <td>6.958</td>\n",
       "      <td>3.855</td>\n",
       "      <td>4.659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FP1    FP2      F7      F8     AF1    AF2     FZ     F4     F3  \\\n",
       "151074  -42.582 -3.662   5.910   5.697   8.382  7.619  6.877  6.409  9.013   \n",
       "2115630  11.587  5.473  15.188  11.983  13.550  6.907  5.229  0.122  5.615   \n",
       "604605   -5.554 -8.077  -1.465  -2.136  -7.853 -6.989 -5.717  1.088 -5.656   \n",
       "805772   -3.296 -0.214  -0.326   5.910  -6.500 -2.736 -7.355 -6.480 -6.317   \n",
       "1490280  -4.547 -3.174  -1.261  -6.042  -5.778 -4.639 -9.084 -3.082 -6.856   \n",
       "\n",
       "           FC6  ...     PO7     PO8    FCZ     POZ      OZ      P2     P1  \\\n",
       "151074   5.056  ...  -2.472   3.174  3.611   0.397   1.007   1.587 -2.299   \n",
       "2115630  2.543  ...   4.415   4.700  3.347   6.460   5.585   4.506  0.254   \n",
       "604605  -1.027  ...  -1.017  -8.321 -1.221 -14.781 -14.191 -11.597 -7.935   \n",
       "805772  -0.783  ...  12.349  18.545 -5.086   8.565  10.010   8.097  8.596   \n",
       "1490280 -1.170  ...   0.661 -11.902 -6.999   8.667   2.665  11.709  9.511   \n",
       "\n",
       "           CPZ      nd       Y  \n",
       "151074  -1.780   3.560   8.759  \n",
       "2115630 -0.214  17.385  18.473  \n",
       "604605  -3.001  -8.006  -4.262  \n",
       "805772   6.053   8.474   8.341  \n",
       "1490280  6.958   3.855   4.659  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>FZ</th>\n",
       "      <th>F4</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC6</th>\n",
       "      <th>...</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151074</th>\n",
       "      <td>-42.582</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>5.910</td>\n",
       "      <td>5.697</td>\n",
       "      <td>8.382</td>\n",
       "      <td>7.619</td>\n",
       "      <td>6.877</td>\n",
       "      <td>6.409</td>\n",
       "      <td>9.013</td>\n",
       "      <td>5.056</td>\n",
       "      <td>...</td>\n",
       "      <td>3.174</td>\n",
       "      <td>3.611</td>\n",
       "      <td>0.397</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.587</td>\n",
       "      <td>-2.299</td>\n",
       "      <td>-1.780</td>\n",
       "      <td>3.560</td>\n",
       "      <td>8.759</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115630</th>\n",
       "      <td>11.587</td>\n",
       "      <td>5.473</td>\n",
       "      <td>15.188</td>\n",
       "      <td>11.983</td>\n",
       "      <td>13.550</td>\n",
       "      <td>6.907</td>\n",
       "      <td>5.229</td>\n",
       "      <td>0.122</td>\n",
       "      <td>5.615</td>\n",
       "      <td>2.543</td>\n",
       "      <td>...</td>\n",
       "      <td>4.700</td>\n",
       "      <td>3.347</td>\n",
       "      <td>6.460</td>\n",
       "      <td>5.585</td>\n",
       "      <td>4.506</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>17.385</td>\n",
       "      <td>18.473</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604605</th>\n",
       "      <td>-5.554</td>\n",
       "      <td>-8.077</td>\n",
       "      <td>-1.465</td>\n",
       "      <td>-2.136</td>\n",
       "      <td>-7.853</td>\n",
       "      <td>-6.989</td>\n",
       "      <td>-5.717</td>\n",
       "      <td>1.088</td>\n",
       "      <td>-5.656</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.321</td>\n",
       "      <td>-1.221</td>\n",
       "      <td>-14.781</td>\n",
       "      <td>-14.191</td>\n",
       "      <td>-11.597</td>\n",
       "      <td>-7.935</td>\n",
       "      <td>-3.001</td>\n",
       "      <td>-8.006</td>\n",
       "      <td>-4.262</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805772</th>\n",
       "      <td>-3.296</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>5.910</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>-2.736</td>\n",
       "      <td>-7.355</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>-6.317</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>...</td>\n",
       "      <td>18.545</td>\n",
       "      <td>-5.086</td>\n",
       "      <td>8.565</td>\n",
       "      <td>10.010</td>\n",
       "      <td>8.097</td>\n",
       "      <td>8.596</td>\n",
       "      <td>6.053</td>\n",
       "      <td>8.474</td>\n",
       "      <td>8.341</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490280</th>\n",
       "      <td>-4.547</td>\n",
       "      <td>-3.174</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-6.042</td>\n",
       "      <td>-5.778</td>\n",
       "      <td>-4.639</td>\n",
       "      <td>-9.084</td>\n",
       "      <td>-3.082</td>\n",
       "      <td>-6.856</td>\n",
       "      <td>-1.170</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.902</td>\n",
       "      <td>-6.999</td>\n",
       "      <td>8.667</td>\n",
       "      <td>2.665</td>\n",
       "      <td>11.709</td>\n",
       "      <td>9.511</td>\n",
       "      <td>6.958</td>\n",
       "      <td>3.855</td>\n",
       "      <td>4.659</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FP1    FP2      F7      F8     AF1    AF2     FZ     F4     F3  \\\n",
       "151074  -42.582 -3.662   5.910   5.697   8.382  7.619  6.877  6.409  9.013   \n",
       "2115630  11.587  5.473  15.188  11.983  13.550  6.907  5.229  0.122  5.615   \n",
       "604605   -5.554 -8.077  -1.465  -2.136  -7.853 -6.989 -5.717  1.088 -5.656   \n",
       "805772   -3.296 -0.214  -0.326   5.910  -6.500 -2.736 -7.355 -6.480 -6.317   \n",
       "1490280  -4.547 -3.174  -1.261  -6.042  -5.778 -4.639 -9.084 -3.082 -6.856   \n",
       "\n",
       "           FC6  ...     PO8    FCZ     POZ      OZ      P2     P1    CPZ  \\\n",
       "151074   5.056  ...   3.174  3.611   0.397   1.007   1.587 -2.299 -1.780   \n",
       "2115630  2.543  ...   4.700  3.347   6.460   5.585   4.506  0.254 -0.214   \n",
       "604605  -1.027  ...  -8.321 -1.221 -14.781 -14.191 -11.597 -7.935 -3.001   \n",
       "805772  -0.783  ...  18.545 -5.086   8.565  10.010   8.097  8.596  6.053   \n",
       "1490280 -1.170  ... -11.902 -6.999   8.667   2.665  11.709  9.511  6.958   \n",
       "\n",
       "             nd       Y     Status  \n",
       "151074    3.560   8.759  alcoholic  \n",
       "2115630  17.385  18.473    control  \n",
       "604605   -8.006  -4.262  alcoholic  \n",
       "805772    8.474   8.341  alcoholic  \n",
       "1490280   3.855   4.659  alcoholic  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"Status\"] = y_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"Alc_test.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF1</th>\n",
       "      <th>AF2</th>\n",
       "      <th>FZ</th>\n",
       "      <th>F4</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC6</th>\n",
       "      <th>...</th>\n",
       "      <th>PO8</th>\n",
       "      <th>FCZ</th>\n",
       "      <th>POZ</th>\n",
       "      <th>OZ</th>\n",
       "      <th>P2</th>\n",
       "      <th>P1</th>\n",
       "      <th>CPZ</th>\n",
       "      <th>nd</th>\n",
       "      <th>Y</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1663690</th>\n",
       "      <td>0.285</td>\n",
       "      <td>2.553</td>\n",
       "      <td>-10.427</td>\n",
       "      <td>5.707</td>\n",
       "      <td>4.618</td>\n",
       "      <td>7.619</td>\n",
       "      <td>5.605</td>\n",
       "      <td>6.978</td>\n",
       "      <td>-2.482</td>\n",
       "      <td>4.191</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.044</td>\n",
       "      <td>1.333</td>\n",
       "      <td>-11.709</td>\n",
       "      <td>-11.078</td>\n",
       "      <td>-7.304</td>\n",
       "      <td>-10.773</td>\n",
       "      <td>-4.842</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-7.477</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592369</th>\n",
       "      <td>5.198</td>\n",
       "      <td>8.057</td>\n",
       "      <td>-5.381</td>\n",
       "      <td>-5.208</td>\n",
       "      <td>7.823</td>\n",
       "      <td>5.361</td>\n",
       "      <td>7.090</td>\n",
       "      <td>4.110</td>\n",
       "      <td>3.916</td>\n",
       "      <td>-4.679</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.515</td>\n",
       "      <td>3.703</td>\n",
       "      <td>-38.045</td>\n",
       "      <td>-61.839</td>\n",
       "      <td>-20.986</td>\n",
       "      <td>-20.518</td>\n",
       "      <td>-8.077</td>\n",
       "      <td>-41.463</td>\n",
       "      <td>-8.189</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701549</th>\n",
       "      <td>6.022</td>\n",
       "      <td>26.265</td>\n",
       "      <td>-20.559</td>\n",
       "      <td>-6.755</td>\n",
       "      <td>-4.608</td>\n",
       "      <td>7.406</td>\n",
       "      <td>2.675</td>\n",
       "      <td>3.235</td>\n",
       "      <td>-8.219</td>\n",
       "      <td>-5.798</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.687</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-34.241</td>\n",
       "      <td>-19.155</td>\n",
       "      <td>-22.644</td>\n",
       "      <td>-12.950</td>\n",
       "      <td>-7.782</td>\n",
       "      <td>-20.854</td>\n",
       "      <td>-20.711</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797964</th>\n",
       "      <td>-9.389</td>\n",
       "      <td>-10.630</td>\n",
       "      <td>-6.694</td>\n",
       "      <td>-12.065</td>\n",
       "      <td>-11.353</td>\n",
       "      <td>-14.821</td>\n",
       "      <td>-12.044</td>\n",
       "      <td>-14.496</td>\n",
       "      <td>-9.501</td>\n",
       "      <td>-12.756</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.463</td>\n",
       "      <td>-7.721</td>\n",
       "      <td>-2.563</td>\n",
       "      <td>-5.422</td>\n",
       "      <td>-2.157</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>-8.881</td>\n",
       "      <td>-4.578</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298383</th>\n",
       "      <td>14.648</td>\n",
       "      <td>17.904</td>\n",
       "      <td>4.537</td>\n",
       "      <td>21.261</td>\n",
       "      <td>7.538</td>\n",
       "      <td>11.210</td>\n",
       "      <td>3.855</td>\n",
       "      <td>9.603</td>\n",
       "      <td>0.875</td>\n",
       "      <td>8.413</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.322</td>\n",
       "      <td>2.024</td>\n",
       "      <td>-1.750</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>19.368</td>\n",
       "      <td>19.368</td>\n",
       "      <td>alcoholic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FP1     FP2      F7      F8     AF1     AF2      FZ      F4  \\\n",
       "1663690   0.285   2.553 -10.427   5.707   4.618   7.619   5.605   6.978   \n",
       "592369    5.198   8.057  -5.381  -5.208   7.823   5.361   7.090   4.110   \n",
       "2701549   6.022  26.265 -20.559  -6.755  -4.608   7.406   2.675   3.235   \n",
       "1797964  -9.389 -10.630  -6.694 -12.065 -11.353 -14.821 -12.044 -14.496   \n",
       "1298383  14.648  17.904   4.537  21.261   7.538  11.210   3.855   9.603   \n",
       "\n",
       "            F3     FC6  ...     PO8    FCZ     POZ      OZ      P2      P1  \\\n",
       "1663690 -2.482   4.191  ... -22.044  1.333 -11.709 -11.078  -7.304 -10.773   \n",
       "592369   3.916  -4.679  ... -54.515  3.703 -38.045 -61.839 -20.986 -20.518   \n",
       "2701549 -8.219  -5.798  ... -18.687  3.367 -34.241 -19.155 -22.644 -12.950   \n",
       "1797964 -9.501 -12.756  ...  -5.463 -7.721  -2.563  -5.422  -2.157  -3.662   \n",
       "1298383  0.875   8.413  ...  -1.322  2.024  -1.750  -0.234  -1.709  -0.356   \n",
       "\n",
       "           CPZ      nd       Y     Status  \n",
       "1663690 -4.842   0.376  -7.477    control  \n",
       "592369  -8.077 -41.463  -8.189  alcoholic  \n",
       "2701549 -7.782 -20.854 -20.711  alcoholic  \n",
       "1797964 -1.709  -8.881  -4.578    control  \n",
       "1298383 -0.142  19.368  19.368  alcoholic  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Status\"] = y_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"Alc_train.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=64))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/60\n",
      " - 112s - loss: 0.4219 - accuracy: 0.8006\n",
      "Epoch 2/60\n",
      " - 81s - loss: 0.3363 - accuracy: 0.8497\n",
      "Epoch 3/60\n",
      " - 81s - loss: 0.3056 - accuracy: 0.8657\n",
      "Epoch 4/60\n",
      " - 82s - loss: 0.2874 - accuracy: 0.8751\n",
      "Epoch 5/60\n",
      " - 82s - loss: 0.2740 - accuracy: 0.8820\n",
      "Epoch 6/60\n",
      " - 82s - loss: 0.2642 - accuracy: 0.8866\n",
      "Epoch 7/60\n",
      " - 92s - loss: 0.2564 - accuracy: 0.8907\n",
      "Epoch 8/60\n",
      " - 81s - loss: 0.2502 - accuracy: 0.8937\n",
      "Epoch 9/60\n",
      " - 82s - loss: 0.2442 - accuracy: 0.8967\n",
      "Epoch 10/60\n",
      " - 82s - loss: 0.2393 - accuracy: 0.8989\n",
      "Epoch 11/60\n",
      " - 83s - loss: 0.2348 - accuracy: 0.9013\n",
      "Epoch 12/60\n",
      " - 84s - loss: 0.2305 - accuracy: 0.9032\n",
      "Epoch 13/60\n",
      " - 87s - loss: 0.2269 - accuracy: 0.9051\n",
      "Epoch 14/60\n",
      " - 85s - loss: 0.2235 - accuracy: 0.9068\n",
      "Epoch 15/60\n",
      " - 86s - loss: 0.2210 - accuracy: 0.9081\n",
      "Epoch 16/60\n",
      " - 87s - loss: 0.2178 - accuracy: 0.9095\n",
      "Epoch 17/60\n",
      " - 93s - loss: 0.2155 - accuracy: 0.9107\n",
      "Epoch 18/60\n",
      " - 90s - loss: 0.2136 - accuracy: 0.9116\n",
      "Epoch 19/60\n",
      " - 88s - loss: 0.2115 - accuracy: 0.9126\n",
      "Epoch 20/60\n",
      " - 89s - loss: 0.2099 - accuracy: 0.9133\n",
      "Epoch 21/60\n",
      " - 90s - loss: 0.2083 - accuracy: 0.9140\n",
      "Epoch 22/60\n",
      " - 91s - loss: 0.2068 - accuracy: 0.9149\n",
      "Epoch 23/60\n",
      " - 91s - loss: 0.2052 - accuracy: 0.9156\n",
      "Epoch 24/60\n",
      " - 95s - loss: 0.2040 - accuracy: 0.9161\n",
      "Epoch 25/60\n",
      " - 94s - loss: 0.2030 - accuracy: 0.9166\n",
      "Epoch 26/60\n",
      " - 95s - loss: 0.2018 - accuracy: 0.9172\n",
      "Epoch 27/60\n",
      " - 96s - loss: 0.2009 - accuracy: 0.9176\n",
      "Epoch 28/60\n",
      " - 98s - loss: 0.1998 - accuracy: 0.9183\n",
      "Epoch 29/60\n",
      " - 97s - loss: 0.1990 - accuracy: 0.9184\n",
      "Epoch 30/60\n",
      " - 96s - loss: 0.1980 - accuracy: 0.9190\n",
      "Epoch 31/60\n",
      " - 96s - loss: 0.1971 - accuracy: 0.9196\n",
      "Epoch 32/60\n",
      " - 95s - loss: 0.1963 - accuracy: 0.9200\n",
      "Epoch 33/60\n",
      " - 96s - loss: 0.1956 - accuracy: 0.9201\n",
      "Epoch 34/60\n",
      " - 100s - loss: 0.1948 - accuracy: 0.9203\n",
      "Epoch 35/60\n",
      " - 95s - loss: 0.1941 - accuracy: 0.9211\n",
      "Epoch 36/60\n",
      " - 96s - loss: 0.1931 - accuracy: 0.9212\n",
      "Epoch 37/60\n",
      " - 106s - loss: 0.1925 - accuracy: 0.9217\n",
      "Epoch 38/60\n",
      " - 130s - loss: 0.1918 - accuracy: 0.9220\n",
      "Epoch 39/60\n",
      " - 99s - loss: 0.1913 - accuracy: 0.9223\n",
      "Epoch 40/60\n",
      " - 98s - loss: 0.1904 - accuracy: 0.9227\n",
      "Epoch 41/60\n",
      " - 99s - loss: 0.1897 - accuracy: 0.9231\n",
      "Epoch 42/60\n",
      " - 98s - loss: 0.1890 - accuracy: 0.9233\n",
      "Epoch 43/60\n",
      " - 97s - loss: 0.1882 - accuracy: 0.9238\n",
      "Epoch 44/60\n",
      " - 96s - loss: 0.1877 - accuracy: 0.9239\n",
      "Epoch 45/60\n",
      " - 105s - loss: 0.1872 - accuracy: 0.9244\n",
      "Epoch 46/60\n",
      " - 114s - loss: 0.1864 - accuracy: 0.9247\n",
      "Epoch 47/60\n",
      " - 99s - loss: 0.1858 - accuracy: 0.9250\n",
      "Epoch 48/60\n",
      " - 97s - loss: 0.1852 - accuracy: 0.9253\n",
      "Epoch 49/60\n",
      " - 98s - loss: 0.1848 - accuracy: 0.9255\n",
      "Epoch 50/60\n",
      " - 100s - loss: 0.1842 - accuracy: 0.9257\n",
      "Epoch 51/60\n",
      " - 98s - loss: 0.1836 - accuracy: 0.9259\n",
      "Epoch 52/60\n",
      " - 100s - loss: 0.1829 - accuracy: 0.9264\n",
      "Epoch 53/60\n",
      " - 99s - loss: 0.1824 - accuracy: 0.9267\n",
      "Epoch 54/60\n",
      " - 97s - loss: 0.1818 - accuracy: 0.9270\n",
      "Epoch 55/60\n",
      " - 96s - loss: 0.1813 - accuracy: 0.9272\n",
      "Epoch 56/60\n",
      " - 97s - loss: 0.1806 - accuracy: 0.9273\n",
      "Epoch 57/60\n",
      " - 98s - loss: 0.1804 - accuracy: 0.9274\n",
      "Epoch 58/60\n",
      " - 99s - loss: 0.1799 - accuracy: 0.9278\n",
      " - 98s - loss: 0.1791 - accuracy: 0.9283\n",
      "Epoch 60/60\n",
      " - 97s - loss: 0.1789 - accuracy: 0.9283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2159992f470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.18364687067484087, Accuracy: 0.9269834756851196\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['alcoholic' 'control' 'alcoholic' 'alcoholic' 'alcoholic']\n",
      "Actual Labels: ['alcoholic', 'control', 'alcoholic', 'alcoholic', 'alcoholic']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"ALC_NN_FDF1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Convolutional Neural Networks in Keras for Time Sequences\n",
    "\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "TIME_PERIODS = 1\n",
    "num_sensors = 64\n",
    "input_shape = 64\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 100)            6500      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 100)            10100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 160)            16160     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 160)            25760     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 322       \n",
      "=================================================================\n",
      "Total params: 58,842\n",
      "Trainable params: 58,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "model_m.add(Conv1D(100, 1, activation='relu', input_shape=(TIME_PERIODS, num_sensors)))\n",
    "model_m.add(Conv1D(100, 1, activation='relu'))\n",
    "model_m.add(MaxPooling1D(1))\n",
    "model_m.add(Conv1D(160, 1, activation='relu'))\n",
    "model_m.add(Conv1D(160, 1, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D())\n",
    "model_m.add(Dropout(0.5))\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1698355 samples, validate on 424589 samples\n",
      "Epoch 1/50\n",
      "1698355/1698355 [==============================] - 95s 56us/step - loss: 0.4488 - accuracy: 0.7841 - val_loss: 0.3793 - val_accuracy: 0.8262\n",
      "Epoch 2/50\n",
      "   3200/1698355 [..............................] - ETA: 1:35 - loss: 0.3921 - accuracy: 0.8191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asi40\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1698355/1698355 [==============================] - 91s 54us/step - loss: 0.3398 - accuracy: 0.8478 - val_loss: 0.3178 - val_accuracy: 0.8585\n",
      "Epoch 3/50\n",
      "1698355/1698355 [==============================] - 113s 66us/step - loss: 0.3003 - accuracy: 0.8683 - val_loss: 0.2861 - val_accuracy: 0.8751\n",
      "Epoch 4/50\n",
      "1698355/1698355 [==============================] - 91s 54us/step - loss: 0.2775 - accuracy: 0.8797 - val_loss: 0.2734 - val_accuracy: 0.8814\n",
      "Epoch 5/50\n",
      "1698355/1698355 [==============================] - 94s 55us/step - loss: 0.2613 - accuracy: 0.8880 - val_loss: 0.2540 - val_accuracy: 0.8911\n",
      "Epoch 6/50\n",
      "1698355/1698355 [==============================] - 92s 54us/step - loss: 0.2479 - accuracy: 0.8946 - val_loss: 0.2503 - val_accuracy: 0.8926\n",
      "Epoch 7/50\n",
      "1698355/1698355 [==============================] - 95s 56us/step - loss: 0.2378 - accuracy: 0.8998 - val_loss: 0.2385 - val_accuracy: 0.8983\n",
      "Epoch 8/50\n",
      "1698355/1698355 [==============================] - 99s 58us/step - loss: 0.2291 - accuracy: 0.9038 - val_loss: 0.2356 - val_accuracy: 0.8997\n",
      "Epoch 9/50\n",
      "1698355/1698355 [==============================] - 94s 55us/step - loss: 0.2212 - accuracy: 0.9078 - val_loss: 0.2234 - val_accuracy: 0.9056\n",
      "Epoch 10/50\n",
      "1698355/1698355 [==============================] - 98s 58us/step - loss: 0.2148 - accuracy: 0.9107 - val_loss: 0.2150 - val_accuracy: 0.9097\n",
      "Epoch 11/50\n",
      "1698355/1698355 [==============================] - 92s 54us/step - loss: 0.2086 - accuracy: 0.9136 - val_loss: 0.2125 - val_accuracy: 0.9112\n",
      "Epoch 12/50\n",
      "1698355/1698355 [==============================] - 90s 53us/step - loss: 0.2029 - accuracy: 0.9162 - val_loss: 0.2064 - val_accuracy: 0.9138\n",
      "Epoch 13/50\n",
      "1698355/1698355 [==============================] - 119s 70us/step - loss: 0.1983 - accuracy: 0.9183 - val_loss: 0.2026 - val_accuracy: 0.9163\n",
      "Epoch 14/50\n",
      "1698355/1698355 [==============================] - 135s 79us/step - loss: 0.1933 - accuracy: 0.9205 - val_loss: 0.1991 - val_accuracy: 0.9176\n",
      "Epoch 15/50\n",
      "1698355/1698355 [==============================] - 127s 75us/step - loss: 0.1898 - accuracy: 0.9223 - val_loss: 0.1995 - val_accuracy: 0.9170\n",
      "Epoch 16/50\n",
      "1698355/1698355 [==============================] - 126s 74us/step - loss: 0.1858 - accuracy: 0.9242 - val_loss: 0.1933 - val_accuracy: 0.9208\n",
      "Epoch 17/50\n",
      "1698355/1698355 [==============================] - 131s 77us/step - loss: 0.1828 - accuracy: 0.9256 - val_loss: 0.1919 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "1698355/1698355 [==============================] - 124s 73us/step - loss: 0.1793 - accuracy: 0.9269 - val_loss: 0.1887 - val_accuracy: 0.9223\n",
      "Epoch 19/50\n",
      "1698355/1698355 [==============================] - 129s 76us/step - loss: 0.1769 - accuracy: 0.9282 - val_loss: 0.1886 - val_accuracy: 0.9229\n",
      "Epoch 20/50\n",
      "1698355/1698355 [==============================] - 137s 81us/step - loss: 0.1741 - accuracy: 0.9293 - val_loss: 0.1851 - val_accuracy: 0.9239\n",
      "Epoch 21/50\n",
      "1698355/1698355 [==============================] - 106s 62us/step - loss: 0.1716 - accuracy: 0.9306 - val_loss: 0.1821 - val_accuracy: 0.9258\n",
      "Epoch 22/50\n",
      "1698355/1698355 [==============================] - 107s 63us/step - loss: 0.1694 - accuracy: 0.9316 - val_loss: 0.1794 - val_accuracy: 0.9267\n",
      "Epoch 23/50\n",
      "1698355/1698355 [==============================] - 108s 64us/step - loss: 0.1668 - accuracy: 0.9327 - val_loss: 0.1762 - val_accuracy: 0.9280\n",
      "Epoch 24/50\n",
      "1698355/1698355 [==============================] - 109s 64us/step - loss: 0.1652 - accuracy: 0.9336 - val_loss: 0.1742 - val_accuracy: 0.9297\n",
      "Epoch 25/50\n",
      "1698355/1698355 [==============================] - 111s 66us/step - loss: 0.1631 - accuracy: 0.9344 - val_loss: 0.1715 - val_accuracy: 0.9302\n",
      "Epoch 26/50\n",
      "1698355/1698355 [==============================] - 113s 66us/step - loss: 0.1615 - accuracy: 0.9352 - val_loss: 0.1679 - val_accuracy: 0.9320\n",
      "Epoch 27/50\n",
      "1698355/1698355 [==============================] - 116s 68us/step - loss: 0.1599 - accuracy: 0.9358 - val_loss: 0.1724 - val_accuracy: 0.9297\n",
      "Epoch 28/50\n",
      "1698355/1698355 [==============================] - 120s 71us/step - loss: 0.1579 - accuracy: 0.9365 - val_loss: 0.1728 - val_accuracy: 0.9304\n",
      "Epoch 29/50\n",
      "1698355/1698355 [==============================] - 115s 68us/step - loss: 0.1551 - accuracy: 0.9379 - val_loss: 0.1653 - val_accuracy: 0.9333\n",
      "Epoch 31/50\n",
      "1698355/1698355 [==============================] - 138s 81us/step - loss: 0.1539 - accuracy: 0.9384 - val_loss: 0.1654 - val_accuracy: 0.9338\n",
      "Epoch 32/50\n",
      "1698355/1698355 [==============================] - 132s 77us/step - loss: 0.1524 - accuracy: 0.9392 - val_loss: 0.1664 - val_accuracy: 0.9334\n",
      "Epoch 33/50\n",
      "1698355/1698355 [==============================] - 141s 83us/step - loss: 0.1511 - accuracy: 0.9399 - val_loss: 0.1624 - val_accuracy: 0.9348\n",
      "Epoch 34/50\n",
      "1698355/1698355 [==============================] - 132s 78us/step - loss: 0.1499 - accuracy: 0.9402 - val_loss: 0.1594 - val_accuracy: 0.9360\n",
      "Epoch 35/50\n",
      "1698355/1698355 [==============================] - 133s 78us/step - loss: 0.1489 - accuracy: 0.9407 - val_loss: 0.1636 - val_accuracy: 0.9340\n",
      "Epoch 36/50\n",
      "1698355/1698355 [==============================] - 125s 74us/step - loss: 0.1480 - accuracy: 0.9410 - val_loss: 0.1575 - val_accuracy: 0.9371\n",
      "Epoch 37/50\n",
      "1698355/1698355 [==============================] - 150s 88us/step - loss: 0.1466 - accuracy: 0.9417 - val_loss: 0.1612 - val_accuracy: 0.9355\n",
      "Epoch 38/50\n",
      "1698355/1698355 [==============================] - 156s 92us/step - loss: 0.1457 - accuracy: 0.9422 - val_loss: 0.1573 - val_accuracy: 0.9375\n",
      "Epoch 39/50\n",
      "1698355/1698355 [==============================] - 163s 96us/step - loss: 0.1448 - accuracy: 0.9425 - val_loss: 0.1602 - val_accuracy: 0.9366\n",
      "Epoch 40/50\n",
      "1698355/1698355 [==============================] - 166s 98us/step - loss: 0.1437 - accuracy: 0.9430 - val_loss: 0.1554 - val_accuracy: 0.9381\n",
      "Epoch 41/50\n",
      "1698355/1698355 [==============================] - 136s 80us/step - loss: 0.1431 - accuracy: 0.9431 - val_loss: 0.1576 - val_accuracy: 0.9376\n",
      "Epoch 42/50\n",
      "1698355/1698355 [==============================] - 135s 79us/step - loss: 0.1419 - accuracy: 0.9438 - val_loss: 0.1564 - val_accuracy: 0.9376\n",
      "Epoch 43/50\n",
      "1698355/1698355 [==============================] - 131s 77us/step - loss: 0.1414 - accuracy: 0.9440 - val_loss: 0.1568 - val_accuracy: 0.9380\n",
      "Epoch 44/50\n",
      "1698355/1698355 [==============================] - 133s 78us/step - loss: 0.1407 - accuracy: 0.9442 - val_loss: 0.1547 - val_accuracy: 0.93920.140\n",
      "Epoch 45/50\n",
      "1698355/1698355 [==============================] - 128s 75us/step - loss: 0.1400 - accuracy: 0.9446 - val_loss: 0.1546 - val_accuracy: 0.9387\n",
      "Epoch 46/50\n",
      "1698355/1698355 [==============================] - 136s 80us/step - loss: 0.1388 - accuracy: 0.9451 - val_loss: 0.1524 - val_accuracy: 0.9405\n",
      "Epoch 47/50\n",
      "1698355/1698355 [==============================] - 138s 82us/step - loss: 0.1381 - accuracy: 0.9455 - val_loss: 0.1539 - val_accuracy: 0.9392\n",
      "Epoch 48/50\n",
      "1698355/1698355 [==============================] - 134s 79us/step - loss: 0.1373 - accuracy: 0.9455 - val_loss: 0.1534 - val_accuracy: 0.9396\n",
      "Epoch 49/50\n",
      "1698355/1698355 [==============================] - 135s 79us/step - loss: 0.1368 - accuracy: 0.9460 - val_loss: 0.1508 - val_accuracy: 0.9408\n",
      "Epoch 50/50\n",
      "1698355/1698355 [==============================] - 128s 75us/step - loss: 0.1361 - accuracy: 0.9462 - val_loss: 0.1530 - val_accuracy: 0.9391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks_list = [keras.callbacks.ModelCheckpoint(filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                                                  monitor='val_loss', save_best_only=True),\n",
    "                  keras.callbacks.EarlyStopping(monitor='acc', patience=1)]\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model_m.fit(X_train_scaled,\n",
    "                      y_train_categorical,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.15301213687099802, Accuracy: 0.9393370747566223\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model_m.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_m.save(\"ALC_1DCNN_FDF.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
